# -*- coding: utf-8 -*-
"""cnnProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CijDKZa1wDUuBGhpLYANKS8gL3B78Cmf
"""

import numpy as np
import pandas as pd
import os
from __future__ import print_function
from __future__ import division
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy
import random
import shutil
from sklearn.metrics import roc_auc_score, accuracy_score , confusion_matrix
from torch.utils.data.sampler import SubsetRandomSampler
import seaborn as sns

#Data consists of train and test folders. Train and Test folders consist of Cancerous and Non cancerous images.
data = r"/content/drive/MyDrive/AI Project"
numClasses = 2
numEpochs = 20
batch_size = 32

#Transform images
transforms_train =  transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize((224,224))  # Corrected Resize argument
])

transforms_test =  transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize((224,224))  # Corrected Resize argument
])

#creating datasets
image_datasets = datasets.ImageFolder(os.path.join(data, 'Train'), transforms_train)
test_datasets = datasets.ImageFolder(os.path.join(data, 'Test'), transforms_test)


train_dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=batch_size, shuffle=True)
valid_dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=batch_size, shuffle=True)
test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=batch_size, shuffle=True)
device = torch.device("cuda:0" if torch.cuda.is_available() else 'cpu')

#resnet101 model
def initialize_model(num_classes):
    model = models.resnet101(pretrained=True)
    num_features = model.fc.in_features
    model.fc = nn.Linear(num_features, num_classes)
    input_size = 224
    return model

model = initialize_model(numClasses)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.00015)
valid_loss_min=np.Inf
val_auc = []
auc_epoch = []

for epoch in range(numEpochs):
      print('Epoch {}/{}'.format(epoch, numEpochs - 1))
      print('-'*10)

      #Train loop
      model.train()
      train_loss = 0
      train_corrects = 0
      #inputs=images, labels=SSA or HP
      for inputs, labels in train_dataloader:
                inputs = inputs.to(device)
                labels = labels.to(device)
                optimizer.zero_grad()
                outputs=model(inputs)
                loss = criterion(outputs, labels)
                #predict the labels
                _, preds = torch.max(outputs, 1)
                loss.backward()
                optimizer.step()
                #calculate train loss and corrects
                train_loss += loss.item() * inputs.size(0)
                train_corrects  += torch.sum(preds==labels.data)

      #Validation loop
      valid_loss=0
      valid_correct=0
      model.eval()
      for inputs, labels in valid_dataloader:
        inputs = inputs.to(device)
        labels = labels.to(device)
        #print("Inputs",inputs)
        #print("Labels",labels)
        optimizer.zero_grad()
        outputs=model(inputs)
        loss = criterion(outputs, labels)
        #predict labels
        _, preds = torch.max(outputs, 1)
        #calculate valid loss and corrects
        valid_loss += loss.item() * inputs.size(0)
        valid_correct += torch.sum(preds==labels.data)

      #calculation loss, accuracy and auc
      train_loss = train_loss / len(train_dataloader.dataset)
      valid_loss =valid_loss / len(valid_dataloader.dataset)
      train_acc = train_corrects.double() / len(train_dataloader.dataset)
      valid_acc=valid_correct.double() / len(valid_dataloader.dataset)

      print('Train Loss: {:.4f}, Train Acc: {:.4f}, Valid Loss: {:.4f}, Valid Acc: {:.4f}'.format(train_loss, train_acc,valid_loss,valid_acc))

      if valid_loss <= valid_loss_min:
        torch.save(model.state_dict(), '/content/drive/MyDrive/resnet_best_model.pt')
        valid_loss_min = valid_loss
        model.load_state_dict(torch.load('/content/drive/MyDrive/resnet_best_model.pt'))

#Test loop
correct = 0
total = 0
test_labels=[]
predicted_labels=[]
pred_probabs = []
pred_y = []
test_y = []
test_x = []
preds = []
with torch.no_grad():
  for input,labels in test_dataloader:
      input = input.to(device)
      labels = labels.to(device)
      output = model(input)
      #predict labels
      _, predicted = torch.max(output,1)
      total += labels.size(0)
      correct += (predicted == labels).sum().item()

      pr = output.detach().cpu().numpy()
      for i in pr:
        preds.append(i)

      pred_probabs.append(output)
      test_x.append(input)
      pred_y.append(predicted)
      test_y.append(labels)
      test_labels.extend(labels.cpu().numpy())
      predicted_labels.extend(predicted.cpu().numpy())


print('Test Accuracy : ',100*correct/total)
# Define the submission file
sample_sub = pd.DataFrame()
sample_sub['label'] = preds

# Save submission file
sample_sub.to_csv('/content/drive/MyDrive/submission.csv', index=False)
test_labels=np.array(test_labels)
predicted_labels=np.array(predicted_labels)

from sklearn.metrics import classification_report, confusion_matrix
#getting the confusion matrix and classification report
cm = confusion_matrix(test_labels, predicted_labels)
sns.heatmap(cm, annot=True, fmt="d")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

print("Classification Report:")
print(classification_report(test_labels, predicted_labels))

# Displaying some sample images
def imshow(img):
    plt.imshow(np.transpose(img, (1, 2, 0)))

dataiter = iter(test_dataloader)
images, labels = next(dataiter)
images = images.numpy()
# plot the images in the batch, along with the corresponding labels
fig = plt.figure(figsize=(25, 4))
# display 20 images
for idx in np.arange(20):
    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])
    imshow(images[idx])
    label = "SSA" if labels[idx].item() == 0 else "HP"
    ax.set_title(label)

plt.show()